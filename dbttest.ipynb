{"cells":[{"cell_type":"code","source":["%sh\n\nnslookup statlas.prod.atl-paas.net"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d6e8524-edd8-4f2c-836c-27da29899178"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Server:\t\t10.0.56.2\nAddress:\t10.0.56.2#53\n\nNon-authoritative answer:\nName:\tstatlas.prod.atl-paas.net\nAddress: 10.202.152.199\nName:\tstatlas.prod.atl-paas.net\nAddress: 10.202.172.251\nName:\tstatlas.prod.atl-paas.net\nAddress: 10.202.131.102\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Server:\t\t10.0.56.2\nAddress:\t10.0.56.2#53\n\nNon-authoritative answer:\nName:\tstatlas.prod.atl-paas.net\nAddress: 10.202.152.199\nName:\tstatlas.prod.atl-paas.net\nAddress: 10.202.172.251\nName:\tstatlas.prod.atl-paas.net\nAddress: 10.202.131.102\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\ncurl https://ne-dmz-atlassian.net.atlassian.com/statlas.prod.atl-paas.net/plato.dev.configs/experimental/manifest.zip\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c752ff8-347c-45c5-8e6d-1a4b69d08b0e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100   234  100   234    0     0  10636      0 --:--:-- --:--:-- --:--:-- 10636\n403 Permission Denied Service not whitelisted. \nenv: dev\nsrc_ip: 10.0.57.85\ndst_ip: 10.202.152.199\ntenant: \nforwardFQDN: statlas.prod.atl-paas.net\npath: /statlas.prod.atl-paas.net/plato.dev.configs/experimental/manifest.zip\nwarning: \n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100   234  100   234    0     0  10636      0 --:--:-- --:--:-- --:--:-- 10636\n403 Permission Denied Service not whitelisted. \nenv: dev\nsrc_ip: 10.0.57.85\ndst_ip: 10.202.152.199\ntenant: \nforwardFQDN: statlas.prod.atl-paas.net\npath: /statlas.prod.atl-paas.net/plato.dev.configs/experimental/manifest.zip\nwarning: \n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"462e105e-5e12-449f-b166-c2bd15692b79"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["token = dbutils.secrets.get('dbt-projects-test', 'DB_DEV_CONSUMER_US_TOKEN')\nprint(len(token))\nprint(token)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1263517-9e1b-43ca-8139-5934489f971d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">36\n[REDACTED]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">36\n[REDACTED]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\ndatabricks secrets list --scope=dbt-projects-test"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ebf88c4-b167-423b-9a76-cc82c2dbd1ba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/bin/bash: databricks: command not found\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/bin/bash: databricks: command not found\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\npip install datadog\npip install zipfile36\npip install pyyaml\npip install pytest-shutil\npip install dbt-databricks\n#dbt init dq_test"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1404848-48d0-48bf-970e-f6f8734a07a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Collecting datadog\n  Downloading datadog-0.44.0-py2.py3-none-any.whl (111 kB)\nRequirement already satisfied: requests&gt;=2.6.0 in /databricks/python3/lib/python3.8/site-packages (from datadog) (2.25.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2.10)\nInstalling collected packages: datadog\nSuccessfully installed datadog-0.44.0\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nCollecting zipfile36\n  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\nInstalling collected packages: zipfile36\nSuccessfully installed zipfile36-0.1.3\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.8/site-packages (6.0)\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nCollecting pytest-shutil\n  Downloading pytest_shutil-1.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from pytest-shutil) (1.15.0)\nCollecting execnet\n  Downloading execnet-1.9.0-py2.py3-none-any.whl (39 kB)\nCollecting mock\n  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\nCollecting termcolor\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting path.py\n  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\nCollecting contextlib2\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting pytest\n  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\nCollecting path\n  Downloading path-16.4.0-py3-none-any.whl (26 kB)\nCollecting iniconfig\n  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\nCollecting py&gt;=1.8.2\n  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\nRequirement already satisfied: attrs&gt;=19.2.0 in /databricks/python3/lib/python3.8/site-packages (from pytest-&gt;pytest-shutil) (20.3.0)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from pytest-&gt;pytest-shutil) (20.9)\nCollecting tomli&gt;=1.0.0\n  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\nCollecting pluggy&lt;2.0,&gt;=0.12\n  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;pytest-&gt;pytest-shutil) (2.4.7)\nBuilding wheels for collected packages: termcolor\n  Building wheel for termcolor (setup.py): started\n  Building wheel for termcolor (setup.py): finished with status &#39;done&#39;\n  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=73f91b7653e68e9ac2ffa49869575809eda6f4f3e6842bc9e9d4e35fa5a84155\n  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\nSuccessfully built termcolor\nInstalling collected packages: tomli, py, pluggy, path, iniconfig, termcolor, pytest, path.py, mock, execnet, contextlib2, pytest-shutil\nSuccessfully installed contextlib2-21.6.0 execnet-1.9.0 iniconfig-1.1.1 mock-4.0.3 path-16.4.0 path.py-12.5.0 pluggy-1.0.0 py-1.11.0 pytest-7.1.2 pytest-shutil-1.7.0 termcolor-1.1.0 tomli-2.0.1\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nRequirement already satisfied: dbt-databricks in /databricks/python3/lib/python3.8/site-packages (1.1.1)\nRequirement already satisfied: dbt-spark~=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-databricks) (1.1.0)\nRequirement already satisfied: databricks-sql-connector&gt;=2.0.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-databricks) (2.0.2)\nRequirement already satisfied: pyarrow&gt;=5.0.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector&gt;=2.0.1-&gt;dbt-databricks) (8.0.0)\nRequirement already satisfied: thrift&gt;=0.13.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector&gt;=2.0.1-&gt;dbt-databricks) (0.16.0)\nRequirement already satisfied: pandas&gt;=1.3.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector&gt;=2.0.1-&gt;dbt-databricks) (1.4.3)\nRequirement already satisfied: dbt-core~=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-spark~=1.1.0-&gt;dbt-databricks) (1.1.2)\nRequirement already satisfied: sqlparams&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-spark~=1.1.0-&gt;dbt-databricks) (4.0.0)\nRequirement already satisfied: colorama&lt;0.4.5,&gt;=0.3.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.4)\nRequirement already satisfied: werkzeug&lt;3,&gt;=1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.1.2)\nRequirement already satisfied: requests&lt;3.0.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.25.1)\nRequirement already satisfied: hologram&lt;=0.0.15,&gt;=0.0.14 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.0.15)\nRequirement already satisfied: agate&lt;1.6.4,&gt;=1.6 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.6.3)\nRequirement already satisfied: typing-extensions&gt;=3.7.4 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.3.0)\nRequirement already satisfied: isodate&lt;0.7,&gt;=0.6 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.6.1)\nRequirement already satisfied: networkx&lt;2.8.4,&gt;=2.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.8.3)\nRequirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (8.1.3)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.10)\nRequirement already satisfied: sqlparse&lt;0.5,&gt;=0.2.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.2)\nRequirement already satisfied: packaging&lt;22.0,&gt;=20.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (20.9)\nRequirement already satisfied: minimal-snowplow-tracker==0.0.2 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.0.2)\nRequirement already satisfied: dbt-extractor~=0.4.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.1)\nRequirement already satisfied: logbook&lt;1.6,&gt;=1.5 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.5.3)\nRequirement already satisfied: mashumaro==2.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.9)\nRequirement already satisfied: Jinja2==2.11.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.11.3)\nRequirement already satisfied: MarkupSafe&lt;2.1,&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.0.1)\nRequirement already satisfied: cffi&lt;2.0.0,&gt;=1.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.14.5)\nRequirement already satisfied: msgpack&gt;=0.5.6 in /databricks/python3/lib/python3.8/site-packages (from mashumaro==2.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.0.4)\nRequirement already satisfied: pyyaml&gt;=3.13 in /databricks/python3/lib/python3.8/site-packages (from mashumaro==2.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (6.0)\nRequirement already satisfied: six&lt;2.0,&gt;=1.9.0 in /databricks/python3/lib/python3.8/site-packages (from minimal-snowplow-tracker==0.0.2-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.15.0)\nRequirement already satisfied: parsedatetime!=2.5,!=2.6,&gt;=2.1 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.4)\nRequirement already satisfied: python-slugify&gt;=1.2.1 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (6.1.2)\nRequirement already satisfied: Babel&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.10.3)\nRequirement already satisfied: leather&gt;=0.3.2 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.3.4)\nRequirement already satisfied: pytimeparse&gt;=1.1.5 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.1.8)\nRequirement already satisfied: pytz&gt;=2015.7 in /databricks/python3/lib/python3.8/site-packages (from Babel&gt;=2.0-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2020.5)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&lt;2.0.0,&gt;=1.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.20)\nRequirement already satisfied: jsonschema&lt;4.0,&gt;=3.0 in /databricks/python3/lib/python3.8/site-packages (from hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (3.2.0)\nRequirement already satisfied: python-dateutil&lt;2.9,&gt;=2.8 in /databricks/python3/lib/python3.8/site-packages (from hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.8.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from jsonschema&lt;4.0,&gt;=3.0-&gt;hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (52.0.0)\nRequirement already satisfied: pyrsistent&gt;=0.14.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;4.0,&gt;=3.0-&gt;hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.17.3)\nRequirement already satisfied: attrs&gt;=17.4.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;4.0,&gt;=3.0-&gt;hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (20.3.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&lt;22.0,&gt;=20.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.4.7)\nRequirement already satisfied: numpy&gt;=1.18.5 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.3.0-&gt;databricks-sql-connector&gt;=2.0.1-&gt;dbt-databricks) (1.19.2)\nRequirement already satisfied: future in /databricks/python3/lib/python3.8/site-packages (from parsedatetime!=2.5,!=2.6,&gt;=2.1-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.18.2)\nRequirement already satisfied: text-unidecode&gt;=1.3 in /databricks/python3/lib/python3.8/site-packages (from python-slugify&gt;=1.2.1-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.25.11)\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Collecting datadog\n  Downloading datadog-0.44.0-py2.py3-none-any.whl (111 kB)\nRequirement already satisfied: requests&gt;=2.6.0 in /databricks/python3/lib/python3.8/site-packages (from datadog) (2.25.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2.10)\nInstalling collected packages: datadog\nSuccessfully installed datadog-0.44.0\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nCollecting zipfile36\n  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\nInstalling collected packages: zipfile36\nSuccessfully installed zipfile36-0.1.3\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.8/site-packages (6.0)\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nCollecting pytest-shutil\n  Downloading pytest_shutil-1.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from pytest-shutil) (1.15.0)\nCollecting execnet\n  Downloading execnet-1.9.0-py2.py3-none-any.whl (39 kB)\nCollecting mock\n  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\nCollecting termcolor\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting path.py\n  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\nCollecting contextlib2\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting pytest\n  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\nCollecting path\n  Downloading path-16.4.0-py3-none-any.whl (26 kB)\nCollecting iniconfig\n  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\nCollecting py&gt;=1.8.2\n  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\nRequirement already satisfied: attrs&gt;=19.2.0 in /databricks/python3/lib/python3.8/site-packages (from pytest-&gt;pytest-shutil) (20.3.0)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from pytest-&gt;pytest-shutil) (20.9)\nCollecting tomli&gt;=1.0.0\n  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\nCollecting pluggy&lt;2.0,&gt;=0.12\n  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;pytest-&gt;pytest-shutil) (2.4.7)\nBuilding wheels for collected packages: termcolor\n  Building wheel for termcolor (setup.py): started\n  Building wheel for termcolor (setup.py): finished with status &#39;done&#39;\n  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=73f91b7653e68e9ac2ffa49869575809eda6f4f3e6842bc9e9d4e35fa5a84155\n  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\nSuccessfully built termcolor\nInstalling collected packages: tomli, py, pluggy, path, iniconfig, termcolor, pytest, path.py, mock, execnet, contextlib2, pytest-shutil\nSuccessfully installed contextlib2-21.6.0 execnet-1.9.0 iniconfig-1.1.1 mock-4.0.3 path-16.4.0 path.py-12.5.0 pluggy-1.0.0 py-1.11.0 pytest-7.1.2 pytest-shutil-1.7.0 termcolor-1.1.0 tomli-2.0.1\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nRequirement already satisfied: dbt-databricks in /databricks/python3/lib/python3.8/site-packages (1.1.1)\nRequirement already satisfied: dbt-spark~=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-databricks) (1.1.0)\nRequirement already satisfied: databricks-sql-connector&gt;=2.0.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-databricks) (2.0.2)\nRequirement already satisfied: pyarrow&gt;=5.0.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector&gt;=2.0.1-&gt;dbt-databricks) (8.0.0)\nRequirement already satisfied: thrift&gt;=0.13.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector&gt;=2.0.1-&gt;dbt-databricks) (0.16.0)\nRequirement already satisfied: pandas&gt;=1.3.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector&gt;=2.0.1-&gt;dbt-databricks) (1.4.3)\nRequirement already satisfied: dbt-core~=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-spark~=1.1.0-&gt;dbt-databricks) (1.1.2)\nRequirement already satisfied: sqlparams&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-spark~=1.1.0-&gt;dbt-databricks) (4.0.0)\nRequirement already satisfied: colorama&lt;0.4.5,&gt;=0.3.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.4)\nRequirement already satisfied: werkzeug&lt;3,&gt;=1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.1.2)\nRequirement already satisfied: requests&lt;3.0.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.25.1)\nRequirement already satisfied: hologram&lt;=0.0.15,&gt;=0.0.14 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.0.15)\nRequirement already satisfied: agate&lt;1.6.4,&gt;=1.6 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.6.3)\nRequirement already satisfied: typing-extensions&gt;=3.7.4 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.3.0)\nRequirement already satisfied: isodate&lt;0.7,&gt;=0.6 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.6.1)\nRequirement already satisfied: networkx&lt;2.8.4,&gt;=2.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.8.3)\nRequirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (8.1.3)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.10)\nRequirement already satisfied: sqlparse&lt;0.5,&gt;=0.2.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.2)\nRequirement already satisfied: packaging&lt;22.0,&gt;=20.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (20.9)\nRequirement already satisfied: minimal-snowplow-tracker==0.0.2 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.0.2)\nRequirement already satisfied: dbt-extractor~=0.4.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.1)\nRequirement already satisfied: logbook&lt;1.6,&gt;=1.5 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.5.3)\nRequirement already satisfied: mashumaro==2.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.9)\nRequirement already satisfied: Jinja2==2.11.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.11.3)\nRequirement already satisfied: MarkupSafe&lt;2.1,&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.0.1)\nRequirement already satisfied: cffi&lt;2.0.0,&gt;=1.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.14.5)\nRequirement already satisfied: msgpack&gt;=0.5.6 in /databricks/python3/lib/python3.8/site-packages (from mashumaro==2.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.0.4)\nRequirement already satisfied: pyyaml&gt;=3.13 in /databricks/python3/lib/python3.8/site-packages (from mashumaro==2.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (6.0)\nRequirement already satisfied: six&lt;2.0,&gt;=1.9.0 in /databricks/python3/lib/python3.8/site-packages (from minimal-snowplow-tracker==0.0.2-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.15.0)\nRequirement already satisfied: parsedatetime!=2.5,!=2.6,&gt;=2.1 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.4)\nRequirement already satisfied: python-slugify&gt;=1.2.1 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (6.1.2)\nRequirement already satisfied: Babel&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.10.3)\nRequirement already satisfied: leather&gt;=0.3.2 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.3.4)\nRequirement already satisfied: pytimeparse&gt;=1.1.5 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.1.8)\nRequirement already satisfied: pytz&gt;=2015.7 in /databricks/python3/lib/python3.8/site-packages (from Babel&gt;=2.0-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2020.5)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&lt;2.0.0,&gt;=1.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.20)\nRequirement already satisfied: jsonschema&lt;4.0,&gt;=3.0 in /databricks/python3/lib/python3.8/site-packages (from hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (3.2.0)\nRequirement already satisfied: python-dateutil&lt;2.9,&gt;=2.8 in /databricks/python3/lib/python3.8/site-packages (from hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.8.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from jsonschema&lt;4.0,&gt;=3.0-&gt;hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (52.0.0)\nRequirement already satisfied: pyrsistent&gt;=0.14.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;4.0,&gt;=3.0-&gt;hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.17.3)\nRequirement already satisfied: attrs&gt;=17.4.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;4.0,&gt;=3.0-&gt;hologram&lt;=0.0.15,&gt;=0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (20.3.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&lt;22.0,&gt;=20.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.4.7)\nRequirement already satisfied: numpy&gt;=1.18.5 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.3.0-&gt;databricks-sql-connector&gt;=2.0.1-&gt;dbt-databricks) (1.19.2)\nRequirement already satisfied: future in /databricks/python3/lib/python3.8/site-packages (from parsedatetime!=2.5,!=2.6,&gt;=2.1-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.18.2)\nRequirement already satisfied: text-unidecode&gt;=1.3 in /databricks/python3/lib/python3.8/site-packages (from python-slugify&gt;=1.2.1-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.25.11)\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\npip install datadog"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b5ea36f-94ce-4ed7-a3e0-6e88a7389d6e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: datadog in ./.local/lib/python3.8/site-packages (0.44.0)\nRequirement already satisfied: requests&gt;=2.6.0 in /databricks/python3/lib/python3.8/site-packages (from datadog) (2.25.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2.10)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: datadog in ./.local/lib/python3.8/site-packages (0.44.0)\nRequirement already satisfied: requests&gt;=2.6.0 in /databricks/python3/lib/python3.8/site-packages (from datadog) (2.25.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2.10)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\nnslookup dp-plato-dmz-dev-us-east-1-statsd-atl-inf-net.net.atlassian.com"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c0b73e2-e92b-4d8e-be63-9f8923cab82e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Server:\t\t10.0.56.2\nAddress:\t10.0.56.2#53\n\nNon-authoritative answer:\ndp-plato-dmz-dev-us-east-1-statsd-atl-inf-net.net.atlassian.com\tcanonical name = vip-04-dmz-dev-useast1.net.atlassian.com.\nName:\tvip-04-dmz-dev-useast1.net.atlassian.com\nAddress: 10.125.18.6\nName:\tvip-04-dmz-dev-useast1.net.atlassian.com\nAddress: 10.125.18.70\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Server:\t\t10.0.56.2\nAddress:\t10.0.56.2#53\n\nNon-authoritative answer:\ndp-plato-dmz-dev-us-east-1-statsd-atl-inf-net.net.atlassian.com\tcanonical name = vip-04-dmz-dev-useast1.net.atlassian.com.\nName:\tvip-04-dmz-dev-useast1.net.atlassian.com\nAddress: 10.125.18.6\nName:\tvip-04-dmz-dev-useast1.net.atlassian.com\nAddress: 10.125.18.70\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["\nfrom datadog import DogStatsd\nimport yaml\nresult = {}\nresult['failures'] = 200\n\ntags = [\"env:dev\", \"region:us-east-1\", \"entity:hack-consumer\", \"quality_dimension:hack\"]\n\n# SIGNALFX_STATSD_HOST = '127.0.0.1'\n\nSIGNALFX_STATSD_HOST = \"dp-plato-dmz-dev-us-east-1-statsd-atl-inf-net.net.atlassian.comzzz\"\n\nsignalfx_statsd_conn = DogStatsd(host=SIGNALFX_STATSD_HOST)\n\nprint(signalfx_statsd_conn)\nprint(result[\"failures\"]/10)\n\nstatus = signalfx_statsd_conn.gauge(\"vipin.metrics.consumer\", result[\"failures\"]/10, tags=tags)\n\nprint(status)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67701b38-cfe5-459a-81b7-39445b237ef4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;datadog.dogstatsd.base.DogStatsd object at 0x7fa65480e940&gt;\n20.0\nNone\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;datadog.dogstatsd.base.DogStatsd object at 0x7fa65480e940&gt;\n20.0\nNone\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["\nfrom datadog import DogStatsd\nresult = {}\nresult['failures'] = 300\n\ntags = [\"env:dev\", \"region:us-east-1\", \"entity:hack-consumer\", \"quality_dimension:hack\"]\n\n# SIGNALFX_STATSD_HOST = '127.0.0.1'\n\nSIGNALFX_STATSD_HOST = \"dp-plato-dmz-dev-us-east-1-statsd-atl-inf-net.net.atlassian.com\"\n\nsignalfx_statsd_conn = DogStatsd(host=SIGNALFX_STATSD_HOST)\n\nprint(signalfx_statsd_conn)\nprint(result[\"failures\"]/10)\n\nsignalfx_statsd_conn.gauge(\"plato.metrics.quality.checks\", result[\"failures\"]/10, tags=tags)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b88d4ca8-f750-426b-bb35-85db52bce313"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;datadog.dogstatsd.base.DogStatsd object at 0x7fa6546c09a0&gt;\n30.0\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;datadog.dogstatsd.base.DogStatsd object at 0x7fa6546c09a0&gt;\n30.0\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from databricks import sql\n\nwith sql.connect(server_hostname=\"atlassian-plato-dev-consumer-us-01.cloud.databricks.com\",\n                 http_path=\"/sql/1.0/endpoints/2e0ffc6b44006fe5\",\n                 access_token=\"dapi7c3d344a5f61ee8ddcf59a541e44e6cc\") as connection:\n    with connection.cursor() as cursor:\n        cursor.execute(\"SELECT * FROM jira_us.project_current LIMIT 2\")\n        result = cursor.fetchall()\n\n        for row in result:\n          print(row)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7c95744-bcb5-4a28-b3b8-643ecd1c78fc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ImportError</span>                               Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2636535851174032&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">from</span> databricks <span class=\"ansi-green-fg\">import</span> sql\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> with sql.connect(server_hostname=&#34;atlassian-plato-dev-consumer-us-01.cloud.databricks.com&#34;,\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                  http_path<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;/sql/1.0/endpoints/2e0ffc6b44006fe5&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>                  access_token=&#34;dapi7c3d344a5f61ee8ddcf59a541e44e6cc&#34;) as connection:\n\n<span class=\"ansi-red-fg\">ImportError</span>: cannot import name &#39;sql&#39; from &#39;databricks&#39; (/databricks/python/lib/python3.8/site-packages/databricks/__init__.py)</div>","errorSummary":"<span class=\"ansi-red-fg\">ImportError</span>: cannot import name &#39;sql&#39; from &#39;databricks&#39; (/databricks/python/lib/python3.8/site-packages/databricks/__init__.py)","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ImportError</span>                               Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2636535851174032&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">from</span> databricks <span class=\"ansi-green-fg\">import</span> sql\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> with sql.connect(server_hostname=&#34;atlassian-plato-dev-consumer-us-01.cloud.databricks.com&#34;,\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                  http_path<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;/sql/1.0/endpoints/2e0ffc6b44006fe5&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>                  access_token=&#34;dapi7c3d344a5f61ee8ddcf59a541e44e6cc&#34;) as connection:\n\n<span class=\"ansi-red-fg\">ImportError</span>: cannot import name &#39;sql&#39; from &#39;databricks&#39; (/databricks/python/lib/python3.8/site-packages/databricks/__init__.py)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\npip install datadog\npip install zipfile36\npip install pyyaml\npip install pytest-shutil\npip install dbt-databricks\n#dbt init dq_test"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1d2d6f6e-1182-420f-a402-658af0084fc6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Collecting datadog\n  Downloading datadog-0.44.0-py2.py3-none-any.whl (111 kB)\nRequirement already satisfied: requests&gt;=2.6.0 in /databricks/python3/lib/python3.8/site-packages (from datadog) (2.25.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2.10)\nInstalling collected packages: datadog\nSuccessfully installed datadog-0.44.0\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nCollecting zipfile36\n  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\nInstalling collected packages: zipfile36\nSuccessfully installed zipfile36-0.1.3\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.8/site-packages (6.0)\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nCollecting pytest-shutil\n  Downloading pytest_shutil-1.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from pytest-shutil) (1.15.0)\nCollecting execnet\n  Downloading execnet-1.9.0-py2.py3-none-any.whl (39 kB)\nCollecting mock\n  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\nCollecting termcolor\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting path.py\n  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\nCollecting contextlib2\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting pytest\n  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\nCollecting path\n  Downloading path-16.4.0-py3-none-any.whl (26 kB)\nCollecting iniconfig\n  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\nCollecting py&gt;=1.8.2\n  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\nRequirement already satisfied: attrs&gt;=19.2.0 in /databricks/python3/lib/python3.8/site-packages (from pytest-&gt;pytest-shutil) (20.3.0)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from pytest-&gt;pytest-shutil) (20.9)\nCollecting tomli&gt;=1.0.0\n  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\nCollecting pluggy&lt;2.0,&gt;=0.12\n  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;pytest-&gt;pytest-shutil) (2.4.7)\nBuilding wheels for collected packages: termcolor\n  Building wheel for termcolor (setup.py): started\n  Building wheel for termcolor (setup.py): finished with status &#39;done&#39;\n  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=a629baa9ce16ccbc565fc9075e75cb32761f87f63bf8d9681417391f4fa3a4a5\n  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\nSuccessfully built termcolor\nInstalling collected packages: tomli, py, pluggy, path, iniconfig, termcolor, pytest, path.py, mock, execnet, contextlib2, pytest-shutil\nSuccessfully installed contextlib2-21.6.0 execnet-1.9.0 iniconfig-1.1.1 mock-4.0.3 path-16.4.0 path.py-12.5.0 pluggy-1.0.0 py-1.11.0 pytest-7.1.2 pytest-shutil-1.7.0 termcolor-1.1.0 tomli-2.0.1\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nRequirement already satisfied: dbt-databricks in /databricks/python3/lib/python3.8/site-packages (1.1.0)\nRequirement already satisfied: databricks-sql-connector!=2.0.0,&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-databricks) (2.0.2)\nRequirement already satisfied: dbt-spark~=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-databricks) (1.1.0)\nRequirement already satisfied: pyarrow&gt;=5.0.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector!=2.0.0,&gt;=1.0.1-&gt;dbt-databricks) (8.0.0)\nRequirement already satisfied: thrift&gt;=0.13.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector!=2.0.0,&gt;=1.0.1-&gt;dbt-databricks) (0.16.0)\nRequirement already satisfied: pandas&gt;=1.3.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector!=2.0.0,&gt;=1.0.1-&gt;dbt-databricks) (1.4.2)\nRequirement already satisfied: dbt-core~=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-spark~=1.1.0-&gt;dbt-databricks) (1.1.0)\nRequirement already satisfied: sqlparams&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-spark~=1.1.0-&gt;dbt-databricks) (3.0.0)\nRequirement already satisfied: colorama&lt;0.4.5,&gt;=0.3.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.4)\nRequirement already satisfied: werkzeug&lt;3,&gt;=1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.1.2)\nRequirement already satisfied: requests&lt;3.0.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.25.1)\nRequirement already satisfied: agate&lt;1.6.4,&gt;=1.6 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.6.3)\nRequirement already satisfied: typing-extensions&gt;=3.7.4 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.2.0)\nRequirement already satisfied: networkx&lt;3,&gt;=2.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.8.2)\nRequirement already satisfied: isodate&lt;0.7,&gt;=0.6 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.6.1)\nRequirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (8.1.3)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.10)\nRequirement already satisfied: sqlparse&lt;0.5,&gt;=0.2.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.2)\nRequirement already satisfied: packaging&lt;22.0,&gt;=20.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (20.9)\nRequirement already satisfied: minimal-snowplow-tracker==0.0.2 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.0.2)\nRequirement already satisfied: dbt-extractor~=0.4.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.1)\nRequirement already satisfied: logbook&lt;1.6,&gt;=1.5 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.5.3)\nRequirement already satisfied: mashumaro==2.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.9)\nRequirement already satisfied: Jinja2==2.11.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.11.3)\nRequirement already satisfied: MarkupSafe==2.0.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.0.1)\nRequirement already satisfied: cffi&lt;2.0.0,&gt;=1.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.14.5)\nRequirement already satisfied: hologram==0.0.14 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.0.14)\nRequirement already satisfied: jsonschema&lt;3.2,&gt;=3.0 in /databricks/python3/lib/python3.8/site-packages (from hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (3.1.1)\nRequirement already satisfied: python-dateutil&lt;2.9,&gt;=2.8 in /databricks/python3/lib/python3.8/site-packages (from hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.8.1)\nRequirement already satisfied: msgpack&gt;=0.5.6 in /databricks/python3/lib/python3.8/site-packages (from mashumaro==2.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.0.3)\nRequirement already satisfied: pyyaml&gt;=3.13 in /databricks/python3/lib/python3.8/site-packages (from mashumaro==2.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (6.0)\nRequirement already satisfied: six&lt;2.0,&gt;=1.9.0 in /databricks/python3/lib/python3.8/site-packages (from minimal-snowplow-tracker==0.0.2-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.15.0)\nRequirement already satisfied: parsedatetime!=2.5,!=2.6,&gt;=2.1 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.4)\nRequirement already satisfied: python-slugify&gt;=1.2.1 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (6.1.2)\nRequirement already satisfied: Babel&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.10.1)\nRequirement already satisfied: leather&gt;=0.3.2 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.3.4)\nRequirement already satisfied: pytimeparse&gt;=1.1.5 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.1.8)\nRequirement already satisfied: pytz&gt;=2015.7 in /databricks/python3/lib/python3.8/site-packages (from Babel&gt;=2.0-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2020.5)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&lt;2.0.0,&gt;=1.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.20)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (52.0.0)\nRequirement already satisfied: pyrsistent&gt;=0.14.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.17.3)\nRequirement already satisfied: importlib-metadata in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.11.4)\nRequirement already satisfied: attrs&gt;=17.4.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (20.3.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&lt;22.0,&gt;=20.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.4.7)\nRequirement already satisfied: numpy&gt;=1.18.5 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.3.0-&gt;databricks-sql-connector!=2.0.0,&gt;=1.0.1-&gt;dbt-databricks) (1.19.2)\nRequirement already satisfied: future in /databricks/python3/lib/python3.8/site-packages (from parsedatetime!=2.5,!=2.6,&gt;=2.1-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.18.2)\nRequirement already satisfied: text-unidecode&gt;=1.3 in /databricks/python3/lib/python3.8/site-packages (from python-slugify&gt;=1.2.1-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.25.11)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata-&gt;jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (3.8.0)\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Collecting datadog\n  Downloading datadog-0.44.0-py2.py3-none-any.whl (111 kB)\nRequirement already satisfied: requests&gt;=2.6.0 in /databricks/python3/lib/python3.8/site-packages (from datadog) (2.25.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.6.0-&gt;datadog) (2.10)\nInstalling collected packages: datadog\nSuccessfully installed datadog-0.44.0\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nCollecting zipfile36\n  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\nInstalling collected packages: zipfile36\nSuccessfully installed zipfile36-0.1.3\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.8/site-packages (6.0)\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nCollecting pytest-shutil\n  Downloading pytest_shutil-1.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from pytest-shutil) (1.15.0)\nCollecting execnet\n  Downloading execnet-1.9.0-py2.py3-none-any.whl (39 kB)\nCollecting mock\n  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\nCollecting termcolor\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting path.py\n  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\nCollecting contextlib2\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting pytest\n  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\nCollecting path\n  Downloading path-16.4.0-py3-none-any.whl (26 kB)\nCollecting iniconfig\n  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\nCollecting py&gt;=1.8.2\n  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\nRequirement already satisfied: attrs&gt;=19.2.0 in /databricks/python3/lib/python3.8/site-packages (from pytest-&gt;pytest-shutil) (20.3.0)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from pytest-&gt;pytest-shutil) (20.9)\nCollecting tomli&gt;=1.0.0\n  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\nCollecting pluggy&lt;2.0,&gt;=0.12\n  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;pytest-&gt;pytest-shutil) (2.4.7)\nBuilding wheels for collected packages: termcolor\n  Building wheel for termcolor (setup.py): started\n  Building wheel for termcolor (setup.py): finished with status &#39;done&#39;\n  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=a629baa9ce16ccbc565fc9075e75cb32761f87f63bf8d9681417391f4fa3a4a5\n  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\nSuccessfully built termcolor\nInstalling collected packages: tomli, py, pluggy, path, iniconfig, termcolor, pytest, path.py, mock, execnet, contextlib2, pytest-shutil\nSuccessfully installed contextlib2-21.6.0 execnet-1.9.0 iniconfig-1.1.1 mock-4.0.3 path-16.4.0 path.py-12.5.0 pluggy-1.0.0 py-1.11.0 pytest-7.1.2 pytest-shutil-1.7.0 termcolor-1.1.0 tomli-2.0.1\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\nRequirement already satisfied: dbt-databricks in /databricks/python3/lib/python3.8/site-packages (1.1.0)\nRequirement already satisfied: databricks-sql-connector!=2.0.0,&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-databricks) (2.0.2)\nRequirement already satisfied: dbt-spark~=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-databricks) (1.1.0)\nRequirement already satisfied: pyarrow&gt;=5.0.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector!=2.0.0,&gt;=1.0.1-&gt;dbt-databricks) (8.0.0)\nRequirement already satisfied: thrift&gt;=0.13.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector!=2.0.0,&gt;=1.0.1-&gt;dbt-databricks) (0.16.0)\nRequirement already satisfied: pandas&gt;=1.3.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-sql-connector!=2.0.0,&gt;=1.0.1-&gt;dbt-databricks) (1.4.2)\nRequirement already satisfied: dbt-core~=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-spark~=1.1.0-&gt;dbt-databricks) (1.1.0)\nRequirement already satisfied: sqlparams&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-spark~=1.1.0-&gt;dbt-databricks) (3.0.0)\nRequirement already satisfied: colorama&lt;0.4.5,&gt;=0.3.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.4)\nRequirement already satisfied: werkzeug&lt;3,&gt;=1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.1.2)\nRequirement already satisfied: requests&lt;3.0.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.25.1)\nRequirement already satisfied: agate&lt;1.6.4,&gt;=1.6 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.6.3)\nRequirement already satisfied: typing-extensions&gt;=3.7.4 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.2.0)\nRequirement already satisfied: networkx&lt;3,&gt;=2.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.8.2)\nRequirement already satisfied: isodate&lt;0.7,&gt;=0.6 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.6.1)\nRequirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (8.1.3)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.10)\nRequirement already satisfied: sqlparse&lt;0.5,&gt;=0.2.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.2)\nRequirement already satisfied: packaging&lt;22.0,&gt;=20.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (20.9)\nRequirement already satisfied: minimal-snowplow-tracker==0.0.2 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.0.2)\nRequirement already satisfied: dbt-extractor~=0.4.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.4.1)\nRequirement already satisfied: logbook&lt;1.6,&gt;=1.5 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.5.3)\nRequirement already satisfied: mashumaro==2.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.9)\nRequirement already satisfied: Jinja2==2.11.3 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.11.3)\nRequirement already satisfied: MarkupSafe==2.0.1 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.0.1)\nRequirement already satisfied: cffi&lt;2.0.0,&gt;=1.9 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.14.5)\nRequirement already satisfied: hologram==0.0.14 in /databricks/python3/lib/python3.8/site-packages (from dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.0.14)\nRequirement already satisfied: jsonschema&lt;3.2,&gt;=3.0 in /databricks/python3/lib/python3.8/site-packages (from hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (3.1.1)\nRequirement already satisfied: python-dateutil&lt;2.9,&gt;=2.8 in /databricks/python3/lib/python3.8/site-packages (from hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.8.1)\nRequirement already satisfied: msgpack&gt;=0.5.6 in /databricks/python3/lib/python3.8/site-packages (from mashumaro==2.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.0.3)\nRequirement already satisfied: pyyaml&gt;=3.13 in /databricks/python3/lib/python3.8/site-packages (from mashumaro==2.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (6.0)\nRequirement already satisfied: six&lt;2.0,&gt;=1.9.0 in /databricks/python3/lib/python3.8/site-packages (from minimal-snowplow-tracker==0.0.2-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.15.0)\nRequirement already satisfied: parsedatetime!=2.5,!=2.6,&gt;=2.1 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.4)\nRequirement already satisfied: python-slugify&gt;=1.2.1 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (6.1.2)\nRequirement already satisfied: Babel&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.10.1)\nRequirement already satisfied: leather&gt;=0.3.2 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.3.4)\nRequirement already satisfied: pytimeparse&gt;=1.1.5 in /databricks/python3/lib/python3.8/site-packages (from agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.1.8)\nRequirement already satisfied: pytz&gt;=2015.7 in /databricks/python3/lib/python3.8/site-packages (from Babel&gt;=2.0-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2020.5)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&lt;2.0.0,&gt;=1.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.20)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (52.0.0)\nRequirement already satisfied: pyrsistent&gt;=0.14.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.17.3)\nRequirement already satisfied: importlib-metadata in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.11.4)\nRequirement already satisfied: attrs&gt;=17.4.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (20.3.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&lt;22.0,&gt;=20.9-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2.4.7)\nRequirement already satisfied: numpy&gt;=1.18.5 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.3.0-&gt;databricks-sql-connector!=2.0.0,&gt;=1.0.1-&gt;dbt-databricks) (1.19.2)\nRequirement already satisfied: future in /databricks/python3/lib/python3.8/site-packages (from parsedatetime!=2.5,!=2.6,&gt;=2.1-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (0.18.2)\nRequirement already satisfied: text-unidecode&gt;=1.3 in /databricks/python3/lib/python3.8/site-packages (from python-slugify&gt;=1.2.1-&gt;agate&lt;1.6.4,&gt;=1.6-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (1.25.11)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata-&gt;jsonschema&lt;3.2,&gt;=3.0-&gt;hologram==0.0.14-&gt;dbt-core~=1.1.0-&gt;dbt-spark~=1.1.0-&gt;dbt-databricks) (3.8.0)\nWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\ncat /dbfs/scripts/monitoring/conf/config.toml\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"015bea5f-fe65-4838-b54e-43cd355c45ef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">heartbeat-enabled=true\nstatser-type=&#39;internal&#39;\nflush-interval=&#39;1s&#39;\nignore-host=true\nbackends=[&#39;stdout&#39;,&#39;statsdaemon&#39;]\njson=true\nserver-mode=&#39;standalone&#39;\n#filters=&#39;spark-streaming-metrics&#39;\n​\n# Optional.  Rate limit for how many bad statsd lines to log per minute.\nbad-lines-per-minute=1000\n​\n# Optional.  The address to actually listen for metrics on.  You may want to set this to 127.0.0.1:8125\nmetrics-addr=&#39;127.0.0.1:8125&#39;\n​\n#default-tags=[&#39;business_unit:data-platform-engineering&#39;, &#39;resource_owner:vtiwari&#39;, &#39;internal_service_name:plato-sfx&#39;, &#39;mode:binary&#39;, &#39;sidecar_version:0.0.1-databricks&#39;]\n​\n​\n[statsdaemon]\naddress = &#34;dp-plato-dmz-dev-us-east-1-statsd-atl-inf-net.net.atlassian.com:8125&#34;\ntcp_transport = false\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">heartbeat-enabled=true\nstatser-type=&#39;internal&#39;\nflush-interval=&#39;1s&#39;\nignore-host=true\nbackends=[&#39;stdout&#39;,&#39;statsdaemon&#39;]\njson=true\nserver-mode=&#39;standalone&#39;\n#filters=&#39;spark-streaming-metrics&#39;\n​\n# Optional.  Rate limit for how many bad statsd lines to log per minute.\nbad-lines-per-minute=1000\n​\n# Optional.  The address to actually listen for metrics on.  You may want to set this to 127.0.0.1:8125\nmetrics-addr=&#39;127.0.0.1:8125&#39;\n​\n#default-tags=[&#39;business_unit:data-platform-engineering&#39;, &#39;resource_owner:vtiwari&#39;, &#39;internal_service_name:plato-sfx&#39;, &#39;mode:binary&#39;, &#39;sidecar_version:0.0.1-databricks&#39;]\n​\n​\n[statsdaemon]\naddress = &#34;dp-plato-dmz-dev-us-east-1-statsd-atl-inf-net.net.atlassian.com:8125&#34;\ntcp_transport = false\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\nls /dbfs/FileStore/dbt-projects/aac_batch/\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f32ce9da-49e3-4ab0-bdcf-b00288826b6f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">aac_batch.zip\nmanifest.json\nprofiles.yml\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">aac_batch.zip\nmanifest.json\nprofiles.yml\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import zipfile\nimport os\nwith zipfile.ZipFile(\"/dbfs/FileStore/dbt-projects/aac_batch/aac_batch.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"/databricks/driver/dbt-projects/\")\n    print(os.listdir(\"/databricks/driver/dbt-projects/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"801b43bf-e6fd-4480-a3a3-68507ebe6f42"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;version=001&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;version=001&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\nls /databricks/driver/dbt-projects/version=001\n\necho \"=======\"\n\nls /databricks/driver/dbt-projects/\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"105776fc-935b-4c10-b645-a73e709ab4f6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python-3.8.2\nPython-3.8.2.tar.xz\ndbt_packages\ndbt_project.yml\nlogs\nmacros\nmodels\npackages.yml\n=======\nversion=001\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python-3.8.2\nPython-3.8.2.tar.xz\ndbt_packages\ndbt_project.yml\nlogs\nmacros\nmodels\npackages.yml\n=======\nversion=001\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\ncd /databricks/driver/dbt-projects/version=001\npwd; ls ; \n\necho \"==============\"\n\ncp /dbfs/FileStore/dbt-projects/aac_batch/profiles.yml /databricks/driver/dbt-projects/\n\nls /databricks/driver/dbt-projects/;\n\ncd /databricks/driver/dbt-projects/aac_batch;\n\nls ../\n\nexport DB_DEV_CONSUMER_US_TOKEN=\"dapi7c3d344a5f61ee8ddcf59a541e44e6cc\"\nexport BITBUCKET_BRANCH=\"master\"\ndbt run --profiles-dir=../ --target=dev-producer-us-jira-us"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7b500a9-6b09-445b-9609-ea7ac8aa211d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/driver/dbt-projects/aac_batch\nREADME.md\nanalyses\ndbt_project.yml\nmacros\nmodels\npackages.yml\nseeds\nsnapshots\ntests\n==============\naac_batch\nprofiles.yml\naac_batch\nprofiles.yml\n21:43:16  Encountered an error while reading profiles:\n21:43:16    ERROR: Runtime Error\n  The profile &#39;aac_batch&#39; does not have a target named &#39;dev-producer-us-jira-us&#39;. The valid target names for this profile are:\n   - dev-consumer-us-jira-us\n   - dev-consumer-us-jira-eu\n   - prod-consumer-us-jira-us\n   - prod-consumer-us-jira-eu\n   - prod-consumer-us-jira-syd\n   - prod-consumer-eu-jira-us\n   - prod-consumer-eu-jira-eu\n   - prod-consumer-eu-jira-syd\n   - prod-consumer-syd-jira-us\n   - prod-consumer-syd-jira-eu\n   - prod-consumer-syd-jira-syd\n21:43:16  Defined profiles:\n21:43:16   - output_configurations\n21:43:16   - aac_batch\n21:43:16  \nFor more information on configuring profiles, please consult the dbt docs:\n\nhttps://docs.getdbt.com/docs/configure-your-profile\n\n21:43:16  Encountered an error:\nRuntime Error\n  Could not run dbt\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/driver/dbt-projects/aac_batch\nREADME.md\nanalyses\ndbt_project.yml\nmacros\nmodels\npackages.yml\nseeds\nsnapshots\ntests\n==============\naac_batch\nprofiles.yml\naac_batch\nprofiles.yml\n21:43:16  Encountered an error while reading profiles:\n21:43:16    ERROR: Runtime Error\n  The profile &#39;aac_batch&#39; does not have a target named &#39;dev-producer-us-jira-us&#39;. The valid target names for this profile are:\n   - dev-consumer-us-jira-us\n   - dev-consumer-us-jira-eu\n   - prod-consumer-us-jira-us\n   - prod-consumer-us-jira-eu\n   - prod-consumer-us-jira-syd\n   - prod-consumer-eu-jira-us\n   - prod-consumer-eu-jira-eu\n   - prod-consumer-eu-jira-syd\n   - prod-consumer-syd-jira-us\n   - prod-consumer-syd-jira-eu\n   - prod-consumer-syd-jira-syd\n21:43:16  Defined profiles:\n21:43:16   - output_configurations\n21:43:16   - aac_batch\n21:43:16  \nFor more information on configuring profiles, please consult the dbt docs:\n\nhttps://docs.getdbt.com/docs/configure-your-profile\n\n21:43:16  Encountered an error:\nRuntime Error\n  Could not run dbt\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\ncp /dbfs/FileStore/dbt-projects/aac_batch/profiles.yml /databricks/driver/dbt-projects/\n\ncd /databricks/driver/dbt-projects/version=001\n\npwd\n\ndbt deps\n\nexport DB_DEV_CONSUMER_US_TOKEN=\"dapi7c3d344a5f61ee8ddcf59a541e44e6cc\"\nexport BITBUCKET_BRANCH=\"master\"\nexport BRANCH_NAME=\"master\"\n\ndbt test --profiles-dir=../ --target=dev-consumer-us-jira-us --select tag:reliability_test_daily"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db39789e-8665-4443-a90e-8e57c824434e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/driver/dbt-projects/version=001\n23:42:37  Running with dbt=1.1.0\n23:42:37  Installing calogica/dbt_expectations\n23:42:38    Installed from version 0.5.6\n23:42:38    Up to date!\n23:42:38  Installing calogica/dbt_date\n23:42:38    Installed from version 0.5.7\n23:42:38    Up to date!\n23:42:38  Installing dbt-labs/dbt_utils\n23:42:38    Installed from version 0.8.5\n23:42:38    Up to date!\n23:42:41  Running with dbt=1.1.0\n23:42:41  Partial parse save file not found. Starting full parse.\n23:42:43  [<span class=\"ansi-yellow-fg\">WARNING</span>]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\nThere are 1 unused configuration paths:\n- models.version=001.example\n\n23:42:43  Found 11 models, 47 tests, 0 snapshots, 0 analyses, 641 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics\n23:42:43  \n23:42:53  Concurrency: 1 threads (target=&#39;dev-consumer-us-jira-us&#39;)\n23:42:53  \n23:42:53  1 of 1 START test not_null_jsm_issue_view_enhanced_workspace_id ................ [RUN]\n23:43:12  1 of 1 PASS not_null_jsm_issue_view_enhanced_workspace_id ...................... [<span class=\"ansi-green-fg\">PASS</span> in 19.23s]\n23:43:12  \n23:43:12  Finished running 1 test in 28.83s.\n23:43:12  \n23:43:12  <span class=\"ansi-green-fg\">Completed successfully</span>\n23:43:12  \n23:43:12  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/driver/dbt-projects/version=001\n23:42:37  Running with dbt=1.1.0\n23:42:37  Installing calogica/dbt_expectations\n23:42:38    Installed from version 0.5.6\n23:42:38    Up to date!\n23:42:38  Installing calogica/dbt_date\n23:42:38    Installed from version 0.5.7\n23:42:38    Up to date!\n23:42:38  Installing dbt-labs/dbt_utils\n23:42:38    Installed from version 0.8.5\n23:42:38    Up to date!\n23:42:41  Running with dbt=1.1.0\n23:42:41  Partial parse save file not found. Starting full parse.\n23:42:43  [<span class=\"ansi-yellow-fg\">WARNING</span>]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\nThere are 1 unused configuration paths:\n- models.version=001.example\n\n23:42:43  Found 11 models, 47 tests, 0 snapshots, 0 analyses, 641 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics\n23:42:43  \n23:42:53  Concurrency: 1 threads (target=&#39;dev-consumer-us-jira-us&#39;)\n23:42:53  \n23:42:53  1 of 1 START test not_null_jsm_issue_view_enhanced_workspace_id ................ [RUN]\n23:43:12  1 of 1 PASS not_null_jsm_issue_view_enhanced_workspace_id ...................... [<span class=\"ansi-green-fg\">PASS</span> in 19.23s]\n23:43:12  \n23:43:12  Finished running 1 test in 28.83s.\n23:43:12  \n23:43:12  <span class=\"ansi-green-fg\">Completed successfully</span>\n23:43:12  \n23:43:12  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\npwd\n\ncat /databricks/driver/dbt-projects/version=001/target/run_results.json"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bad01021-2abc-4aff-984b-be4d16618bc6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/driver\n{&#34;metadata&#34;: {&#34;dbt_schema_version&#34;: &#34;https://schemas.getdbt.com/dbt/run-results/v4.json&#34;, &#34;dbt_version&#34;: &#34;1.1.0&#34;, &#34;generated_at&#34;: &#34;2022-05-25T23:43:12.720010Z&#34;, &#34;invocation_id&#34;: &#34;56cfda75-5972-4cd6-a0d1-eca9cda947c9&#34;, &#34;env&#34;: {}}, &#34;results&#34;: [{&#34;status&#34;: &#34;pass&#34;, &#34;timing&#34;: [{&#34;name&#34;: &#34;compile&#34;, &#34;started_at&#34;: &#34;2022-05-25T23:42:53.337854Z&#34;, &#34;completed_at&#34;: &#34;2022-05-25T23:42:53.350290Z&#34;}, {&#34;name&#34;: &#34;execute&#34;, &#34;started_at&#34;: &#34;2022-05-25T23:42:53.350806Z&#34;, &#34;completed_at&#34;: &#34;2022-05-25T23:43:12.392429Z&#34;}], &#34;thread_id&#34;: &#34;Thread-1&#34;, &#34;execution_time&#34;: 19.227410554885864, &#34;adapter_response&#34;: {}, &#34;message&#34;: null, &#34;failures&#34;: 0, &#34;unique_id&#34;: &#34;test.aac_batch.not_null_jsm_issue_view_enhanced_workspace_id.1a1f35ef54&#34;}], &#34;elapsed_time&#34;: 28.826757431030273, &#34;args&#34;: {&#34;write_json&#34;: true, &#34;use_colors&#34;: true, &#34;printer_width&#34;: 80, &#34;version_check&#34;: true, &#34;partial_parse&#34;: true, &#34;static_parser&#34;: true, &#34;profiles_dir&#34;: &#34;/databricks/driver/dbt-projects&#34;, &#34;send_anonymous_usage_stats&#34;: true, &#34;event_buffer_size&#34;: 100000, &#34;quiet&#34;: false, &#34;no_print&#34;: false, &#34;target&#34;: &#34;dev-consumer-us-jira-us&#34;, &#34;indirect_selection&#34;: &#34;eager&#34;, &#34;select&#34;: [&#34;tag:reliability_test_daily&#34;], &#34;which&#34;: &#34;test&#34;, &#34;rpc_method&#34;: &#34;test&#34;}}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/driver\n{&#34;metadata&#34;: {&#34;dbt_schema_version&#34;: &#34;https://schemas.getdbt.com/dbt/run-results/v4.json&#34;, &#34;dbt_version&#34;: &#34;1.1.0&#34;, &#34;generated_at&#34;: &#34;2022-05-25T23:43:12.720010Z&#34;, &#34;invocation_id&#34;: &#34;56cfda75-5972-4cd6-a0d1-eca9cda947c9&#34;, &#34;env&#34;: {}}, &#34;results&#34;: [{&#34;status&#34;: &#34;pass&#34;, &#34;timing&#34;: [{&#34;name&#34;: &#34;compile&#34;, &#34;started_at&#34;: &#34;2022-05-25T23:42:53.337854Z&#34;, &#34;completed_at&#34;: &#34;2022-05-25T23:42:53.350290Z&#34;}, {&#34;name&#34;: &#34;execute&#34;, &#34;started_at&#34;: &#34;2022-05-25T23:42:53.350806Z&#34;, &#34;completed_at&#34;: &#34;2022-05-25T23:43:12.392429Z&#34;}], &#34;thread_id&#34;: &#34;Thread-1&#34;, &#34;execution_time&#34;: 19.227410554885864, &#34;adapter_response&#34;: {}, &#34;message&#34;: null, &#34;failures&#34;: 0, &#34;unique_id&#34;: &#34;test.aac_batch.not_null_jsm_issue_view_enhanced_workspace_id.1a1f35ef54&#34;}], &#34;elapsed_time&#34;: 28.826757431030273, &#34;args&#34;: {&#34;write_json&#34;: true, &#34;use_colors&#34;: true, &#34;printer_width&#34;: 80, &#34;version_check&#34;: true, &#34;partial_parse&#34;: true, &#34;static_parser&#34;: true, &#34;profiles_dir&#34;: &#34;/databricks/driver/dbt-projects&#34;, &#34;send_anonymous_usage_stats&#34;: true, &#34;event_buffer_size&#34;: 100000, &#34;quiet&#34;: false, &#34;no_print&#34;: false, &#34;target&#34;: &#34;dev-consumer-us-jira-us&#34;, &#34;indirect_selection&#34;: &#34;eager&#34;, &#34;select&#34;: [&#34;tag:reliability_test_daily&#34;], &#34;which&#34;: &#34;test&#34;, &#34;rpc_method&#34;: &#34;test&#34;}}</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh \n\nls /databricks/driver/dbt-projects/aac_batch/models/jira"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2056dee5-1b5b-4f13-937a-31d9669d3be1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">issue_cycle_time_enhanced.sql\nissue_cycle_time_enhanced_schema.yml\nissue_estimate_history_enhanced.sql\nissue_estimate_history_enhanced_schema.yml\nissue_field_enhanced.sql\nissue_field_enhanced_schema.yml\nissue_sprint_history_enhanced.sql\nissue_sprint_history_enhanced_schema.yml\nissue_status_history_enhanced.sql\nissue_status_history_enhanced_schema.yml\njira_issue_enhanced.sql\njira_issue_enhanced_schema.yml\njira_issue_history_enhanced.sql\njira_issue_history_enhanced_schema.yml\njira_project_enhanced.sql\njira_project_enhanced_schema.yml\njsm_change_enhanced.sql\njsm_change_enhanced_schema.yml\njsm_incident_enhanced.sql\njsm_incident_enhanced_schemas.yml\njsm_issue_view_enhanced.sql\njsm_issue_view_enhanced_schema.yml\ntables\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">issue_cycle_time_enhanced.sql\nissue_cycle_time_enhanced_schema.yml\nissue_estimate_history_enhanced.sql\nissue_estimate_history_enhanced_schema.yml\nissue_field_enhanced.sql\nissue_field_enhanced_schema.yml\nissue_sprint_history_enhanced.sql\nissue_sprint_history_enhanced_schema.yml\nissue_status_history_enhanced.sql\nissue_status_history_enhanced_schema.yml\njira_issue_enhanced.sql\njira_issue_enhanced_schema.yml\njira_issue_history_enhanced.sql\njira_issue_history_enhanced_schema.yml\njira_project_enhanced.sql\njira_project_enhanced_schema.yml\njsm_change_enhanced.sql\njsm_change_enhanced_schema.yml\njsm_incident_enhanced.sql\njsm_incident_enhanced_schemas.yml\njsm_issue_view_enhanced.sql\njsm_issue_view_enhanced_schema.yml\ntables\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import zipfile\nimport shutil\nimport os\nimport yaml\nimport sys\nimport subprocess\nfrom io import open\n\nclass DbtAction:\n    def __init__( self ):\n        self.DBT_PROJECT_LOCATION = '/databricks/driver/dbt-projects/'\n\n    def switch_working_directory(self, version):\n        os.chdir(self.DBT_PROJECT_LOCATION + \"version=001\")\n\n    def install_dependencies(self):\n        cmd = Command(\"dbt deps;\")\n        cmd.execute()\n\n\n    def test_command(self, profile, tag_selection_clause):\n        base_command = \"\"\"\n          dbt test  --profiles-dir=../ --target=\"\"\" + profile + \"\"\" --select=\"\"\" + tag_selection_clause\n        return Command(base_command)\n\n    def run_command(self, profile, variables, selection_clause):\n        base_command = \"\"\"\n            dbt run --profiles-dir=../  --vars=\"\"\" + variables + \"\"\" --target=\"\"\" + profile\n\n        if selection_clause != 'all':\n            return Command(base_command + \"\"\" --select=\"\"\" + selection_clause)\n        else:\n            return Command(base_command)\n\nclass Command():\n    def __init__( self, cmd ):\n        self.cmd = cmd\n    def print_cmd(self):\n        print(self.cmd)\n    def execute( self ):\n        final = subprocess.Popen(self.cmd, stdout=subprocess.PIPE, shell=True)\n        stdout, nothing = final.communicate()\n        print(\"Command Run stdout: \"+str(stdout))\n        print(\"Command Run nothing: \"+str(nothing))\n        log = open('log', 'wb')\n        log.write(stdout)\n        log.close()\n        final.terminate()\n\nclass Setup:\n    def __init__( self ):\n        self.FILESTORE_PATH =  '/dbfs/FileStore/'\n        self.DBT_PROJECT_LOCATION = 'dbt-projects/'\n\n    def extract_project_directory(self, project):\n        print(\"Extracting project: ----> \"+self.FILESTORE_PATH + self.DBT_PROJECT_LOCATION + project + '/' + project + '.zip')\n        with zipfile.ZipFile(self.FILESTORE_PATH + self.DBT_PROJECT_LOCATION + project + '/' + project + '.zip', 'r') as zip_ref:\n            zip_ref.extractall(\"/databricks/driver/\"+self.DBT_PROJECT_LOCATION)\n        print(os.listdir(\"/databricks/driver/\"+self.DBT_PROJECT_LOCATION))\n\n    def copy_profiles(self, project, profiles):\n        print(\"Copying file : --->> \"+'/dbfs/FileStore/dbt-projects/' + project + '/profiles.yml', '/databricks/driver/dbt-projects/'+profiles)\n        shutil.copy('/dbfs/FileStore/dbt-projects/' + project + '/profiles.yml', '/databricks/driver/dbt-projects/'+profiles)\n\n    def lookup_profile_token(self, profile):\n        print(\"looking up token: --> \"+profile)\n        with open('/databricks/driver/dbt-projects/profiles.yml') as file:\n            data_loaded = yaml.safe_load(file)\n        profiles = data_loaded['version=001']['outputs']\n        token_string = profiles[profile]['token']\n        token_name = token_string.replace(\"{{ env_var('\",'').replace(\"') }}\",'')\n        return token_name\n\n\n# env, region, source directory, schedule_time--> db_job's\nFILESTORE_PATH =  '/dbfs/FileStore/'\nDBT_PROJECT_LOCATION = 'dbt-projects/'\n\nproject = \"aac_batch\"\nprofile = \"dev-consumer-us-jira-us\"\nversion = \"version=001\"\nbranch_name = \"non-master\"\nvariables = \"'{\\\"namespace\\\":\\\"jira_us\\\"}'\"\nselection_clause = \"tag:reliability_test_daily\"\ndbt_action_arg = \"test\"\n\ndbt_setup = Setup()\ndbt_action = DbtAction()\n\ndef initialize(project, profile_file):\n    print(\"Triggering Project extract: \"+project+\" for profiles defined in : \"+profile_file)\n    dbt_setup.extract_project_directory(project)\n    dbt_setup.copy_profiles(project, profile_file)\n\ndef execute(project, profile, branch_name, variables, selection_clause):\n    env = os.environ\n    token_name = dbt_setup.lookup_profile_token(profile)\n    env[token_name] = dbutils.secrets.get('dbt-projects-test',token_name)\n    env['BRANCH_NAME'] = branch_name\n    env['BITBUCKET_BRANCH'] = branch_name\n\n    dbt_action.switch_working_directory(project)\n    dbt_action.install_dependencies()\n\n    if dbt_action_arg == \"run\":\n        print(\"Execute dbt run command....\")\n        cmd = dbt_action.run_command(profile, variables, selection_clause)\n    elif dbt_action_arg == \"test\":\n        print(\"Execute dbt test command....\")\n        cmd = dbt_action.test_command(profile, selection_clause)\n\n    cmd.execute()\n\n\ninitialize(project, \"profiles.yml\")\nexecute(project, profile, branch_name, variables, selection_clause)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b87e866f-994a-4c2d-b158-205fa44ddd31"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Triggering Project extract: aac_batch for profiles defined in : profiles.yml\nExtracting project: ----&gt; /dbfs/FileStore/dbt-projects/aac_batch/aac_batch.zip\n[&#39;profiles.yml&#39;, &#39;.user.yml&#39;, &#39;version=001&#39;]\nCopying file : ---&gt;&gt; /dbfs/FileStore/dbt-projects/aac_batch/profiles.yml /databricks/driver/dbt-projects/profiles.yml\nlooking up token: --&gt; dev-consumer-us-jira-us\nCommand Run stdout: b&#39;23:53:16  Running with dbt=1.1.0\\n23:53:17  Installing calogica/dbt_expectations\\n23:53:17    Installed from version 0.5.6\\n23:53:17    Up to date!\\n23:53:17  Installing calogica/dbt_date\\n23:53:17    Installed from version 0.5.7\\n23:53:17    Up to date!\\n23:53:17  Installing dbt-labs/dbt_utils\\n23:53:17    Installed from version 0.8.5\\n23:53:17    Up to date!\\n&#39;\nCommand Run nothing: None\nExecute dbt test command....\nCommand Run stdout: b&#34;23:53:20  Running with dbt=1.1.0\\n23:53:20  Unable to do partial parsing because env vars used in profiles.yml have changed\\n23:53:22  [\\x1b[33mWARNING\\x1b[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\\nThere are 1 unused configuration paths:\\n- models.version=001.example\\n\\n23:53:23  Found 11 models, 47 tests, 0 snapshots, 0 analyses, 641 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics\\n23:53:23  \\n23:53:25  Concurrency: 1 threads (target=&#39;dev-consumer-us-jira-us&#39;)\\n23:53:25  \\n23:53:25  1 of 1 START test not_null_jsm_issue_view_enhanced_workspace_id ................ [RUN]\\n23:53:45  1 of 1 PASS not_null_jsm_issue_view_enhanced_workspace_id ...................... [\\x1b[32mPASS\\x1b[0m in 19.13s]\\n23:53:45  \\n23:53:45  Finished running 1 test in 22.35s.\\n23:53:45  \\n23:53:45  \\x1b[32mCompleted successfully\\x1b[0m\\n23:53:45  \\n23:53:45  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\\n&#34;\nCommand Run nothing: None\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Triggering Project extract: aac_batch for profiles defined in : profiles.yml\nExtracting project: ----&gt; /dbfs/FileStore/dbt-projects/aac_batch/aac_batch.zip\n[&#39;profiles.yml&#39;, &#39;.user.yml&#39;, &#39;version=001&#39;]\nCopying file : ---&gt;&gt; /dbfs/FileStore/dbt-projects/aac_batch/profiles.yml /databricks/driver/dbt-projects/profiles.yml\nlooking up token: --&gt; dev-consumer-us-jira-us\nCommand Run stdout: b&#39;23:53:16  Running with dbt=1.1.0\\n23:53:17  Installing calogica/dbt_expectations\\n23:53:17    Installed from version 0.5.6\\n23:53:17    Up to date!\\n23:53:17  Installing calogica/dbt_date\\n23:53:17    Installed from version 0.5.7\\n23:53:17    Up to date!\\n23:53:17  Installing dbt-labs/dbt_utils\\n23:53:17    Installed from version 0.8.5\\n23:53:17    Up to date!\\n&#39;\nCommand Run nothing: None\nExecute dbt test command....\nCommand Run stdout: b&#34;23:53:20  Running with dbt=1.1.0\\n23:53:20  Unable to do partial parsing because env vars used in profiles.yml have changed\\n23:53:22  [\\x1b[33mWARNING\\x1b[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\\nThere are 1 unused configuration paths:\\n- models.version=001.example\\n\\n23:53:23  Found 11 models, 47 tests, 0 snapshots, 0 analyses, 641 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics\\n23:53:23  \\n23:53:25  Concurrency: 1 threads (target=&#39;dev-consumer-us-jira-us&#39;)\\n23:53:25  \\n23:53:25  1 of 1 START test not_null_jsm_issue_view_enhanced_workspace_id ................ [RUN]\\n23:53:45  1 of 1 PASS not_null_jsm_issue_view_enhanced_workspace_id ...................... [\\x1b[32mPASS\\x1b[0m in 19.13s]\\n23:53:45  \\n23:53:45  Finished running 1 test in 22.35s.\\n23:53:45  \\n23:53:45  \\x1b[32mCompleted successfully\\x1b[0m\\n23:53:45  \\n23:53:45  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\\n&#34;\nCommand Run nothing: None\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import sys\nimport os\nimport yaml\nimport json\nfrom io import open\nfrom datadog import DogStatsd\n\nclass DreChecks:\n    def __init__( self ):\n            self.metrics_client = Metrics()\n    \n    def collect_all_models(self, version, project):\n        models_list = []\n\n        for root, dirs, files in os.walk(version+'/models/'+project+\"/jira\"):\n            for filename in files:\n                if filename.lower().endswith('.yml'):\n                    with open(os.path.join(root, filename), \"r\") as stream:\n                        try:\n                            model_name = yaml.safe_load(stream)[\"models\"][0][\"name\"]\n                            models_list.append(model_name)\n                        except yaml.YAMLError as exc:\n                            print(exc)\n\n        return models_list\n\n\n\n    def generate_metrics(self, models_list, version, env=\"dev\", region=\"us-east-1\"):\n        with open(version+'/target/run_results.json', 'r') as f:\n            data = json.load(f)\n\n            for model_name in models_list:\n\n                for result in data['results']:\n                    if result['status'] == 'fail':\n                        error_msg = result['message']\n                        test_name = result['unique_id'].split(\".\")[2]\n\n                        if model_name in test_name:\n                            tmp_test_unique_id = test_name.replace(model_name, \"DQ_Table\")\n                            test_name = tmp_test_unique_id.split(\"_DQ_Table_\")[0]\n                            column_name_list = tmp_test_unique_id.split(\"_DQ_Table_\")[1].split(\"__\")\n\n                            metrics_tags = self.metrics_client.build_metrics_tags(env, region, model_name, test_name)\n                            self.metrics_client.send_metrics(\"plato.metrics.quality.checks\", result[\"failures\"], metrics_tags)\n                    else:\n                        metrics_tags = self.metrics_client.build_metrics_tags(env, region, model_name, \"\")\n                        self.metrics_client.send_metrics(\"plato.metrics.quality.checks\", 0, metrics_tags)\n\nclass Metrics():\n    def __init__( self ):\n        self.SIGNALFX_STATSD_HOST = '127.0.0.1'\n        self.signalfx_statsd_conn = DogStatsd(host=self.SIGNALFX_STATSD_HOST)\n\n    def build_metrics_tags(self, env, region, model_name, test_name):\n        tags = [\"env:\"+env, \"region:\"+region, \"entity:\"+model_name, \"quality_dimension:\"+test_name]\n\n        return tags\n\n    def send_metrics(self, metrics_name, metrics_value, metrics_tags):\n        self.signalfx_statsd_conn.gauge(metrics_name, metrics_value, tags=metrics_tags)\n\n\n# env, region, source directory, schedule_time--> db_job's\nFILESTORE_PATH =  '/dbfs/FileStore/'\nDBT_PROJECT_LOCATION = 'dbt-projects/'\n\nproject = \"aac_batch\"\nversion = \"version=001\"\nenv = \"dev\"\nregion = \"us-east-1\"\n\ndre_checks = DreChecks()\n\nos.chdir(\"/databricks/driver/\"+DBT_PROJECT_LOCATION)\n\nmodels_list = dre_checks.collect_all_models(version, project)\ndre_checks.generate_metrics(models_list, version)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cace2033-682b-49cb-9119-428b1edd8bf7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\npip install pyyaml"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e554d700-69f0-4392-8c4a-6d58396c9641"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pyyaml in ./.local/lib/python3.8/site-packages (6.0)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pyyaml in ./.local/lib/python3.8/site-packages (6.0)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import argparse\nimport os\nimport subprocess\n\nfrom src.dre.db_job import DbJobSetup\nfrom src.dre.utils.config import DBFS_PATH_PREFIX\n\n\nclass DbtAction:\n    def __init__(\n        self,\n        project,\n        product,\n        profile,\n        version,\n        variables,\n        dbt_command,\n        selection_clause,\n    ):\n        self.project = project\n        self.product = product\n        self.profile = profile\n        self.version = version\n        self.variables = variables\n        self.dbt_command = dbt_command\n        self.selection_clause = selection_clause\n\n    def install_dependencies(self):\n        os.chdir(DBFS_PATH_PREFIX + self.version)\n        self.execute_cmd(\"dbt deps;\")\n\n    def build_base_arguments(self):\n        return f\"--profiles-dir=../ --vars={self.variables} --target={self.profile}\"\n\n    def build_models_clauses(self):\n        return f\" --models {self.project}.{self.product}\"\n\n    def build_dbt_test_command(self):\n        print(f\"Building Command for Dbt {self.dbt_command} \")\n        dbt_command_args = self.build_base_arguments() + self.build_models_clauses()\n\n        print(\n            f\"Final Dbt Command :---> dbt {self.dbt_command} {dbt_command_args} --select {self.selection_clause}\"\n        )\n        return self.execute_cmd(\n            f\"dbt {self.dbt_command} {dbt_command_args} --select {self.selection_clause}\"\n        )\n\n    @staticmethod\n    def execute_cmd(cmd):\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)\n        stdout, stderr = process.communicate()\n        if process.returncode != 0:\n            print(\"Command ran with error: \" + str(stderr))\n        else:\n            print(\"Command ran: \" + str(stdout))\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\"--project\", type=str, help=\"batch, realtime\", required=True)\n    parser.add_argument(\"--product\", help=\"jira, opsgenie \", required=True)\n    parser.add_argument(\"--profile\", help=\"consumer profile\", required=True)\n    parser.add_argument(\"--version\", help=\"module version\", required=True)\n    parser.add_argument(\"--branch\", help=\"branch\", required=True)\n    parser.add_argument(\"--variables\", help=\"dbt variables\", required=True)\n    parser.add_argument(\"--selection_clause\", help=\"selection_clause\", required=True)\n    parser.add_argument(\n        \"--dbt_action_arg\", help=\"action to run\", required=True, choices=[\"test\", \"run\"]\n    )\n\n    args = parser.parse_args()\n\n    dbfs_job_setup = DbJobSetup(args.project, args.profile, args.version)\n\n    dbfs_job_setup.copy_profiles()\n    dbfs_job_setup.find_token()\n\n    dbt_action = DbtAction(\n        args.project,\n        args.product,\n        args.profile,\n        args.version,\n        args.variables,\n        args.dbt_command,\n        args.selection_clause,\n    )\n    dbt_action.install_dependencies()\n    dbt_action.build_dbt_test_command()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a51dad6-7d77-43cd-b7f7-e79573e5263f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Triggering Project extract: aac_batch for profiles defined in : profiles.yml\nExtracting project: ----&gt; /dbfs/FileStore/dbt-projects/aac_batch/aac_batch.zip\nCopying file : ---&gt;&gt; /dbfs/FileStore/dbt-projects/aac_batch/profiles.yml to /dbfs/FileStore/dbt-projects/profiles.yml\nLooking up token: --&gt; dev-consumer-us-jira-us\nListing dirs at path : [&#39;.user.yml&#39;, &#39;aac_batch&#39;, &#39;job-scripts&#39;, &#39;profiles.yml&#39;, &#39;src&#39;, &#39;version=001&#39;, &#39;version_001&#39;]\nPresent working directory : /dbfs/FileStore/dbt-projects/version_001\nListing dirs in version folde : [&#39;dbt_packages&#39;, &#39;dbt_project.yml&#39;, &#39;logs&#39;, &#39;macros&#39;, &#39;manifest.json&#39;, &#39;models&#39;, &#39;packages.yml&#39;, &#39;plugins&#39;, &#39;profiles.yml&#39;, &#39;sources&#39;, &#39;target&#39;, &#39;tests&#39;]\nCommand Run stdout: b&#39;07:38:55  Running with dbt=1.1.1\\n07:38:55  Installing calogica/dbt_expectations\\n07:39:26    Installed from version 0.5.8\\n07:39:26    Up to date!\\n07:39:26  Installing calogica/dbt_date\\n07:39:43    Installed from version 0.5.7\\n07:39:43    Up to date!\\n07:39:43  Installing dbt-labs/dbt_utils\\n07:41:03    Installed from version 0.8.6\\n07:41:03    Up to date!\\n&#39;\nCommand Run nothing: None\nExecute dbt test command.....\nBuilding Command for Dbt test \nFinal Dbt Command :---&gt; dbt test --profiles-dir=../ --vars=&#39;{&#34;namespace&#34;:&#34;jira_us&#34;,&#34;region&#34;:&#34;us&#34;}&#39; --target=dev-consumer-us-jira-us --models aac_batch.jira --select tag:reliability_test_hourly\nCommand Run stdout: b&#34;07:41:07  Running with dbt=1.1.1\\n07:41:08  Unable to do partial parsing because a project dependency has been added\\n07:41:34  [\\x1b[33mWARNING\\x1b[0m]: Did not find matching node for patch with name &#39;opsgenie_notification&#39; in the &#39;models&#39; section of file &#39;models/aac_batch/opsgenie/opsgenie_notification.yml&#39;\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Did not find matching node for patch with name &#39;opsgenie_notification_raw&#39; in the &#39;models&#39; section of file &#39;models/aac_batch/opsgenie/opsgenie_notification_raw.yml&#39;\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.not_null_opsgenie_notification_workspace_id.048cb864ae&#39; (models/aac_batch/opsgenie/opsgenie_notification.yml) depends on a node named &#39;opsgenie_notification&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.not_null_opsgenie_notification_is_mass_notification.4f889337e4&#39; (models/aac_batch/opsgenie/opsgenie_notification.yml) depends on a node named &#39;opsgenie_notification&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.ensure_non_tomstoned_row_is_persisted_opsgenie_notification_.59f93de777&#39; (models/aac_batch/opsgenie/opsgenie_notification.yml) depends on a node named &#39;opsgenie_notification&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.ensure_tombstoned_row_is_deleted_opsgenie_notification_.f75b5e83b7&#39; (models/aac_batch/opsgenie/opsgenie_notification.yml) depends on a node named &#39;opsgenie_notification&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.not_null_opsgenie_notification_raw_workspace_id.ed2d7dfdf5&#39; (models/aac_batch/opsgenie/opsgenie_notification_raw.yml) depends on a node named &#39;opsgenie_notification_raw&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\\nThere are 2 unused configuration paths:\\n- models.version_001.aac_batch.opsgenie\\n- models.version_001.aac_batch.jsm_cmdb\\n\\n07:41:35  Found 11 models, 65 tests, 0 snapshots, 0 analyses, 662 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics\\n07:41:35  \\n07:41:46  Concurrency: 16 threads (target=&#39;dev-consumer-us-jira-us&#39;)\\n07:41:46  \\n07:41:46  1 of 3 START test dbt_expectations_expect_table_columns_to_contain_set_jsm_issue_view_enhanced_workspace_id__shard_id__resource_ari__issue_id  [RUN]\\n07:41:46  2 of 3 START test not_null_jsm_issue_view_enhanced_issue_id .................... [RUN]\\n07:41:46  3 of 3 START test not_null_jsm_issue_view_enhanced_workspace_id ................ [RUN]\\n07:41:49  1 of 3 PASS dbt_expectations_expect_table_columns_to_contain_set_jsm_issue_view_enhanced_workspace_id__shard_id__resource_ari__issue_id  [\\x1b[32mPASS\\x1b[0m in 2.90s]\\n07:42:04  2 of 3 PASS not_null_jsm_issue_view_enhanced_issue_id .......................... [\\x1b[32mPASS\\x1b[0m in 18.05s]\\n07:42:04  3 of 3 PASS not_null_jsm_issue_view_enhanced_workspace_id ...................... [\\x1b[32mPASS\\x1b[0m in 18.27s]\\n07:42:04  \\n07:42:04  Finished running 3 tests in 29.19s.\\n07:42:05  \\n07:42:05  \\x1b[32mCompleted successfully\\x1b[0m\\n07:42:05  \\n07:42:05  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3\\n&#34;\nCommand Run nothing: None\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Triggering Project extract: aac_batch for profiles defined in : profiles.yml\nExtracting project: ----&gt; /dbfs/FileStore/dbt-projects/aac_batch/aac_batch.zip\nCopying file : ---&gt;&gt; /dbfs/FileStore/dbt-projects/aac_batch/profiles.yml to /dbfs/FileStore/dbt-projects/profiles.yml\nLooking up token: --&gt; dev-consumer-us-jira-us\nListing dirs at path : [&#39;.user.yml&#39;, &#39;aac_batch&#39;, &#39;job-scripts&#39;, &#39;profiles.yml&#39;, &#39;src&#39;, &#39;version=001&#39;, &#39;version_001&#39;]\nPresent working directory : /dbfs/FileStore/dbt-projects/version_001\nListing dirs in version folde : [&#39;dbt_packages&#39;, &#39;dbt_project.yml&#39;, &#39;logs&#39;, &#39;macros&#39;, &#39;manifest.json&#39;, &#39;models&#39;, &#39;packages.yml&#39;, &#39;plugins&#39;, &#39;profiles.yml&#39;, &#39;sources&#39;, &#39;target&#39;, &#39;tests&#39;]\nCommand Run stdout: b&#39;07:38:55  Running with dbt=1.1.1\\n07:38:55  Installing calogica/dbt_expectations\\n07:39:26    Installed from version 0.5.8\\n07:39:26    Up to date!\\n07:39:26  Installing calogica/dbt_date\\n07:39:43    Installed from version 0.5.7\\n07:39:43    Up to date!\\n07:39:43  Installing dbt-labs/dbt_utils\\n07:41:03    Installed from version 0.8.6\\n07:41:03    Up to date!\\n&#39;\nCommand Run nothing: None\nExecute dbt test command.....\nBuilding Command for Dbt test \nFinal Dbt Command :---&gt; dbt test --profiles-dir=../ --vars=&#39;{&#34;namespace&#34;:&#34;jira_us&#34;,&#34;region&#34;:&#34;us&#34;}&#39; --target=dev-consumer-us-jira-us --models aac_batch.jira --select tag:reliability_test_hourly\nCommand Run stdout: b&#34;07:41:07  Running with dbt=1.1.1\\n07:41:08  Unable to do partial parsing because a project dependency has been added\\n07:41:34  [\\x1b[33mWARNING\\x1b[0m]: Did not find matching node for patch with name &#39;opsgenie_notification&#39; in the &#39;models&#39; section of file &#39;models/aac_batch/opsgenie/opsgenie_notification.yml&#39;\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Did not find matching node for patch with name &#39;opsgenie_notification_raw&#39; in the &#39;models&#39; section of file &#39;models/aac_batch/opsgenie/opsgenie_notification_raw.yml&#39;\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.not_null_opsgenie_notification_workspace_id.048cb864ae&#39; (models/aac_batch/opsgenie/opsgenie_notification.yml) depends on a node named &#39;opsgenie_notification&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.not_null_opsgenie_notification_is_mass_notification.4f889337e4&#39; (models/aac_batch/opsgenie/opsgenie_notification.yml) depends on a node named &#39;opsgenie_notification&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.ensure_non_tomstoned_row_is_persisted_opsgenie_notification_.59f93de777&#39; (models/aac_batch/opsgenie/opsgenie_notification.yml) depends on a node named &#39;opsgenie_notification&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.ensure_tombstoned_row_is_deleted_opsgenie_notification_.f75b5e83b7&#39; (models/aac_batch/opsgenie/opsgenie_notification.yml) depends on a node named &#39;opsgenie_notification&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Test &#39;test.version_001.not_null_opsgenie_notification_raw_workspace_id.ed2d7dfdf5&#39; (models/aac_batch/opsgenie/opsgenie_notification_raw.yml) depends on a node named &#39;opsgenie_notification_raw&#39; which was not found\\n07:41:35  [\\x1b[33mWARNING\\x1b[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\\nThere are 2 unused configuration paths:\\n- models.version_001.aac_batch.opsgenie\\n- models.version_001.aac_batch.jsm_cmdb\\n\\n07:41:35  Found 11 models, 65 tests, 0 snapshots, 0 analyses, 662 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics\\n07:41:35  \\n07:41:46  Concurrency: 16 threads (target=&#39;dev-consumer-us-jira-us&#39;)\\n07:41:46  \\n07:41:46  1 of 3 START test dbt_expectations_expect_table_columns_to_contain_set_jsm_issue_view_enhanced_workspace_id__shard_id__resource_ari__issue_id  [RUN]\\n07:41:46  2 of 3 START test not_null_jsm_issue_view_enhanced_issue_id .................... [RUN]\\n07:41:46  3 of 3 START test not_null_jsm_issue_view_enhanced_workspace_id ................ [RUN]\\n07:41:49  1 of 3 PASS dbt_expectations_expect_table_columns_to_contain_set_jsm_issue_view_enhanced_workspace_id__shard_id__resource_ari__issue_id  [\\x1b[32mPASS\\x1b[0m in 2.90s]\\n07:42:04  2 of 3 PASS not_null_jsm_issue_view_enhanced_issue_id .......................... [\\x1b[32mPASS\\x1b[0m in 18.05s]\\n07:42:04  3 of 3 PASS not_null_jsm_issue_view_enhanced_workspace_id ...................... [\\x1b[32mPASS\\x1b[0m in 18.27s]\\n07:42:04  \\n07:42:04  Finished running 3 tests in 29.19s.\\n07:42:05  \\n07:42:05  \\x1b[32mCompleted successfully\\x1b[0m\\n07:42:05  \\n07:42:05  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3\\n&#34;\nCommand Run nothing: None\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\nls /dbfs/FileStore/\n\npwd"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee7e2173-e41f-475d-ba41-c548d4d3a4db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">ls: cannot access &#39;/dbfs/FileStore/&#39;: No such file or directory\n/home/spark-fbf9d475-b56e-46c8-a544-3a\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ls: cannot access &#39;/dbfs/FileStore/&#39;: No such file or directory\n/home/spark-fbf9d475-b56e-46c8-a544-3a\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import zipfile\nimport os\n\nDBFS_PATH_PREFIX = \"/dbfs/FileStore/dbt-projects/\"\n\n\ndef extract_project_directory(self):\n    if os.path.exists(f\"{DBFS_PATH_PREFIX}{self.project}/{self.project}.zip\"):\n        print(f\"Extracting project: ----> {DBFS_PATH_PREFIX}{self.project}/{self.project}.zip\")\n\n        with zipfile.ZipFile(f\"{DBFS_PATH_PREFIX}{self.project}/{self.project}.zip\", \"r\") as zip_ref:\n            zip_ref.extractall(DBFS_PATH_PREFIX)\n    else:\n        raise FileNotFoundError(f\"{DBFS_PATH_PREFIX}{self.project}/{self.project}.zip does not exist\")\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c0eb79f3-99e7-419e-ad1d-ffd399cfdc47"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import sys\nimport os\n\npythonpath = os.getenv('PYTHONPATH')\nprint(pythonpath+\":/dbfs/FileStore/dbt-projects/\")\n\nsys.path.append('/dbfs/FileStore/dbt-projects/')\n\nos.environ['PYTHONPATH'] = pythonpath+\":/dbfs/FileStore/dbt-projects/\"\n\nprint(f\"Printing SysPath :----> {sys.path}\\n\\n\")\nprint(f\"Printing PYTHONPATH :----> {os.getenv('PYTHONPATH')}\\n\\n\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01b5cdc3-8f05-4d62-880b-bece2fc4d62d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python:/databricks/spark/python/lib/py4j-0.10.9-src.zip:/databricks/jars/spark--driver--driver-spark_3.1_2.12_deploy.jar:/databricks/spark/python:/databricks/python_shell:/dbfs/FileStore/dbt-projects/:/dbfs/FileStore/dbt-projects/\nPrinting SysPath :----&gt; [&#39;/databricks/python_shell/scripts&#39;, &#39;/local_disk0/spark-57b5f37a-c698-4722-a627-854a960be296/userFiles-9cd0da15-050e-4ce5-9b7d-51a0b1131a90&#39;, &#39;/databricks/spark/python&#39;, &#39;/databricks/spark/python/lib/py4j-0.10.9-src.zip&#39;, &#39;/databricks/jars/spark--driver--driver-spark_3.1_2.12_deploy.jar&#39;, &#39;/databricks/python_shell&#39;, &#39;/usr/lib/python38.zip&#39;, &#39;/usr/lib/python3.8&#39;, &#39;/usr/lib/python3.8/lib-dynload&#39;, &#39;/local_disk0/pythonVirtualEnvDirs/virtualEnv-fbf9d475-b56e-46c8-a544-3a606be50709/lib/python3.8/site-packages&#39;, &#39;/databricks/python/lib/python3.8/site-packages&#39;, &#39;/usr/local/lib/python3.8/dist-packages&#39;, &#39;/usr/lib/python3/dist-packages&#39;, &#39;/databricks/python/lib/python3.8/site-packages/IPython/extensions&#39;, &#39;/dbfs/FileStore/dbt-projects/&#39;]\n\n\nPrinting PYTHONPATH :----&gt; /databricks/spark/python:/databricks/spark/python/lib/py4j-0.10.9-src.zip:/databricks/jars/spark--driver--driver-spark_3.1_2.12_deploy.jar:/databricks/spark/python:/databricks/python_shell:/dbfs/FileStore/dbt-projects/:/dbfs/FileStore/dbt-projects/\n\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python:/databricks/spark/python/lib/py4j-0.10.9-src.zip:/databricks/jars/spark--driver--driver-spark_3.1_2.12_deploy.jar:/databricks/spark/python:/databricks/python_shell:/dbfs/FileStore/dbt-projects/:/dbfs/FileStore/dbt-projects/\nPrinting SysPath :----&gt; [&#39;/databricks/python_shell/scripts&#39;, &#39;/local_disk0/spark-57b5f37a-c698-4722-a627-854a960be296/userFiles-9cd0da15-050e-4ce5-9b7d-51a0b1131a90&#39;, &#39;/databricks/spark/python&#39;, &#39;/databricks/spark/python/lib/py4j-0.10.9-src.zip&#39;, &#39;/databricks/jars/spark--driver--driver-spark_3.1_2.12_deploy.jar&#39;, &#39;/databricks/python_shell&#39;, &#39;/usr/lib/python38.zip&#39;, &#39;/usr/lib/python3.8&#39;, &#39;/usr/lib/python3.8/lib-dynload&#39;, &#39;/local_disk0/pythonVirtualEnvDirs/virtualEnv-fbf9d475-b56e-46c8-a544-3a606be50709/lib/python3.8/site-packages&#39;, &#39;/databricks/python/lib/python3.8/site-packages&#39;, &#39;/usr/local/lib/python3.8/dist-packages&#39;, &#39;/usr/lib/python3/dist-packages&#39;, &#39;/databricks/python/lib/python3.8/site-packages/IPython/extensions&#39;, &#39;/dbfs/FileStore/dbt-projects/&#39;]\n\n\nPrinting PYTHONPATH :----&gt; /databricks/spark/python:/databricks/spark/python/lib/py4j-0.10.9-src.zip:/databricks/jars/spark--driver--driver-spark_3.1_2.12_deploy.jar:/databricks/spark/python:/databricks/python_shell:/dbfs/FileStore/dbt-projects/:/dbfs/FileStore/dbt-projects/\n\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\necho $PYTHONPATH\n\n# cd plugins/component/plato/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21965f47-2c10-4f29-bdc1-bd60ae17d997"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python:/databricks/spark/python/lib/py4j-0.10.9-src.zip:/databricks/jars/spark--driver--driver-spark_3.1_2.12_deploy.jar:/databricks/spark/python:/databricks/python_shell\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python:/databricks/spark/python/lib/py4j-0.10.9-src.zip:/databricks/jars/spark--driver--driver-spark_3.1_2.12_deploy.jar:/databricks/spark/python:/databricks/python_shell\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e628e1a8-6aea-4832-9d14-2e6bc4ce2bda"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"dbt test","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2636535851174031}},"nbformat":4,"nbformat_minor":0}
